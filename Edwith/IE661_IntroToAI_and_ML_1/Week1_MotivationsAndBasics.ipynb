{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivations and Basics\n",
    "\n",
    "Machine Learning\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n",
    "- Reinforcement Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MLE\n",
    "\n",
    "Maximum Likelihood Estimation : 관측된 데이터들의 확률을 최대화하는 $\\theta$를 찾아 내는 것.\n",
    "> $\\hat\\theta = \\text{argmax}_\\theta P(D \\mid \\theta)$\n",
    "\n",
    "i.i.d\n",
    "- independent events (독립적인 사건이어야 한다.)\n",
    "- identically distributed according to binomical distribution(각 시행 때마다 각 사건의 확률이 항상 일정해야 한다.)\n",
    "\n",
    "보통 수식을 전개 시 풀어내기 쉽지 않기 때문에(제곱 등) 보통 로그 변환을 거친다. 로그는 [단조함수](https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%A1%B0%ED%95%A8%EC%88%98)이기 때문에 로그 변환 전 함수의 최대점이 로그 함수에서도 최대점이다. 하지만 로그 변환을 하면 지수함수를 선형함수로 바꿔줄 수 있다. (일반적인 값 자체는 달라지지만 max, min 값은 같다.) 그후 최대값은 미분해서 극점을 찾아내면 된다.\n",
    "> $\\hat\\theta = \\text{argmax}_\\theta P(D \\mid \\theta) = \\text{argmax}_\\theta \\ln\\{\\theta^{\\alpha_H}(1 - \\theta)^{\\alpha_T}\\} = \\text{argmax}_\\theta\\{\\alpha_H ln\\theta + \\alpha_T ln(1 - \\theta)\\}$    \n",
    "\n",
    "> ${d \\over d\\theta} (\\alpha_H ln\\theta + \\alpha_T ln(1 - \\theta)) = 0$    \n",
    "\n",
    "> ${\\alpha_H \\over \\theta} - {\\alpha_T \\over 1 - \\theta} = 0$\n",
    "\n",
    "> $\\theta = {\\alpha_H \\over \\alpha_T + \\alpha_H}$\n",
    "\n",
    "> $\\therefore \\; \\hat\\theta = {\\alpha_H \\over \\alpha_T + \\alpha_H}$\n",
    "\n",
    "$\\theta$의 값을 정확히 알 수는 없다. 하지만 시행을 여러번 할수록 Error가 줄어든다. \n",
    "> $P(\\mid\\hat\\theta - \\theta^*\\mid \\; \\ge \\varepsilon) \\le 2e^{-2N\\varepsilon^2}$\n",
    "\n",
    "최적화된 $\\theta$값과 실제 $\\theta$값의 차이(오차). $\\varepsilon$ (허용할수 있는, 특정한 error bound). $\\varepsilon$가 커질수록, N(시행횟수)가 많아질수록 오차가 허용범위를 벗어날 확률은 줄어든다. : 지수가 -이므로 커질수록 오른쪽 항의 수는 작아진다.\n",
    "\n",
    "Probably Approximate Correct (PAC) learning\n",
    "\n",
    ":: 사전 지식없이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\theta \\mid D) = {{P(D \\mid \\theta) P(\\theta)} \\over P(D)}$    \n",
    "$Posterior = {Likelihood \\times Prior Knowledge} \\over Normalizing Constant$\n",
    "\n",
    "관측값이 많지 않을 때 MLE와 MAP는 다른 값이 나올 수 있지만, 관측값이 무수히 많아지면 같은 값을 가지게 된다.\n",
    "![week1_1.png](images/week1_1.png)\n",
    "\n",
    ":: 사전 지식 있이 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability and Distribution\n",
    "\n",
    "![week1_2.png](images/week1_2.png)\n",
    "![week1_3.png](images/week1_3.png)\n",
    "![week1_4.png](images/week1_4.png)\n",
    "\n",
    "- Normal Distribution\n",
    "![week1_5.png](images/week1_5.png)\n",
    "- Beta Distribution : 롱테일이 없다. 따라서 범위가 정해져 있는 경우 쓰기 좋다 - 확률(0 ~ 1)\n",
    "![week1_6.png](images/week1_6.png)\n",
    "- Binomial Distribution\n",
    "![week1_7.png](images/week1_7.png)\n",
    "- Multinomial Distribution : Binomial의 특수한 경우. 텍스트 마이닝에 주로 쓰인다.\n",
    "![week1_8.png](images/week1_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quiz\n",
    "\n",
    "![week1_9.png](images/week1_9.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
